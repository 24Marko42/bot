# parsers.py

import random  # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
from typing import List, Optional  # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
import aiohttp  # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ HTTP-–∑–∞–ø—Ä–æ—Å—ã
from bs4 import BeautifulSoup  # –ü–∞—Ä—Å–∏–Ω–≥ HTML-–∫–æ–Ω—Ç–µ–Ω—Ç–∞

# –ë–∞–∑–æ–≤—ã–µ URL-–∞–¥—Ä–µ—Å–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞
BASE_URL: str = "https://shop.tastycoffee.ru"  # –û—Å–Ω–æ–≤–Ω–æ–π –¥–æ–º–µ–Ω —Å–∞–π—Ç–∞
TASTY_URL_TEMPLATE: str = "https://shop.tastycoffee.ru/coffee?page={}"  # –®–∞–±–ª–æ–Ω URL –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü —Å –∫–æ—Ñ–µ
API_COFFEE_LIST_URL: str = "https://api.sampleapis.com/coffee/hot"  # API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∫–æ—Ñ–µ

async def fetch_html(session: aiohttp.ClientSession, url: str) -> Optional[str]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç HTML-–∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É URL.
    
    Args:
        session: –°–µ—Å—Å–∏—è aiohttp –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
        url: URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        
    Returns:
        HTML-–∫–æ–Ω—Ç–µ–Ω—Ç –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º GET-–∑–∞–ø—Ä–æ—Å —Å —Ç–∞–π–º–∞—É—Ç–æ–º 10 —Å–µ–∫—É–Ω–¥
        async with session.get(url, timeout=10) as resp:
            if resp.status == 200:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω—ã–π —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
                return await resp.text()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
    except:
        return None  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None –ø—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ

async def translate_text(text: str, dest: str = "ru") -> str:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π —è–∑—ã–∫ —Å –ø–æ–º–æ—â—å—é Google Translate API.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
        dest: –Ø–∑—ã–∫ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä—É—Å—Å–∫–∏–π)
        
    Returns:
        –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    import urllib.parse  # –ò–º–ø–æ—Ä—Ç –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    
    try:
        # –ö–æ–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ URL
        encoded = urllib.parse.quote(text)
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è Google Translate API
        url = (
            f"https://translate.googleapis.com/translate_a/single"
            f"?client=gtx&sl=auto&tl={dest}&dt=t&q={encoded}"
        )
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status != 200:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞
                    return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
                
                # –ü–∞—Ä—Å–∏–º JSON-–æ—Ç–≤–µ—Ç
                arr = await resp.json()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–∂–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
                if isinstance(arr, list) and arr and isinstance(arr[0], list):
                    return arr[0][0][0]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                else:
                    return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
    except:
        return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ

async def parse_coffee_page(url: str, limit: int = 5) -> List[str]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∫–æ—Ñ–µ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö.
    
    Args:
        url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∫–æ—Ñ–µ
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö
    """
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º HTML
    async with aiohttp.ClientSession() as session:
        html = await fetch_html(session, url)
        if not html:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
            return ["‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ tastycoffee.ru"]

    # –ü–∞—Ä—Å–∏–º HTML —Å –ø–æ–º–æ—â—å—é BeautifulSoup
    soup = BeautifulSoup(html, "html.parser")
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    items = soup.select("div.product-item")
    results: List[str] = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–æ–¥—É–∫—Ç –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞
    for idx, item in enumerate(items):
        if idx >= limit:
            break

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞
        title_tag = item.select_one("div.tc-tile__title a")
        if not title_tag:
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è
            
        name_en = title_tag.get_text(strip=True)  # –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        name_ru = await translate_text(name_en, dest="ru")  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π
        rel_link = title_tag.get("href", "").strip()  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞
        full_link = BASE_URL + rel_link  # –ü–æ–ª–Ω–∞—è —Å—Å—ã–ª–∫–∞

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
        price_tag = item.select_one("span.text-nowrap")
        price_text = price_tag.get_text(strip=True) if price_tag else "‚Äî"  # –¢–µ–∫—Å—Ç —Ü–µ–Ω—ã

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        desc_container = item.select_one("div.tc-tile__description")
        if desc_container:
            description_p = desc_container.find("p", class_="text-[14px]")
            if description_p:
                # –ü–æ–ª—É—á–∞–µ–º –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ
                description_en = description_p.get_text(separator=" ", strip=True)
                description_ru = await translate_text(description_en, dest="ru")
            else:
                description_ru = ""  # –ü—É—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        else:
            description_ru = ""  # –ü—É—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –Ω–µ—Ç

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∫—É—Å–æ–≤—ã–µ –Ω–æ—Ç—ã
        notes_list = []
        if desc_container and description_p:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å –Ω–æ—Ç–∞–º–∏ –≤–∫—É—Å–∞
            for span in description_p.find_all("span", class_="descriptor-badge"):
                notes_list.append(span.get_text(strip=True))
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–æ—Ç—ã –≤ —Å—Ç—Ä–æ–∫—É
        notes_text = ", ".join(notes_list) if notes_list else "‚Äî"

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞
        results.append(
            f"‚òï <b>{name_ru}</b>\n"
            f"üí∞ {price_text}\n"
            f"üîó <a href=\"{full_link}\">–°—Å—ã–ª–∫–∞</a>\n\n"
            f"‚ÑπÔ∏è <i>{description_ru}</i>\n\n"
            f"–ù–æ—Ç—ã –≤–∫—É—Å–∞: {notes_text}"
        )

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    if not results:
        return ["‚ÑπÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ."]
    return results

async def get_coffee_list() -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å–æ—Ä—Ç–æ–≤ –∫–æ—Ñ–µ –∏–∑ API.
    
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Å–æ—Ä—Ç–æ–≤
    """
    try:
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ API
        async with aiohttp.ClientSession() as session:
            async with session.get(API_COFFEE_LIST_URL) as resp:
                data = await resp.json()  # –ü–∞—Ä—Å–∏–º JSON-–æ—Ç–≤–µ—Ç
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}"  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    lines = ["–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–æ—Ä—Ç–∞:"]
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    for item in data[:10]:
        en = item.get("title", "‚Äî")  # –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        ru = await translate_text(en, dest="ru")  # –†—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        lines.append(f"‚Ä¢ {ru}")  # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
        
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏
    return "\n".join(lines)

async def get_coffee_random() -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —Å–æ—Ä—Ç –∫–æ—Ñ–µ –∏–∑ API.
    
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–ª—É—á–∞–π–Ω–æ–º –∫–æ—Ñ–µ
    """
    try:
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ API
        async with aiohttp.ClientSession() as session:
            async with session.get(API_COFFEE_LIST_URL) as resp:
                data = await resp.json()  # –ü–∞—Ä—Å–∏–º JSON-–æ—Ç–≤–µ—Ç
    except:
        return "–û—à–∏–±–∫–∞ API"  # –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
    item = random.choice(data)
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
    title = item.get("title", "‚Äî")
    desc = item.get("description", "‚Äî")
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π
    title_ru = await translate_text(title, dest="ru")
    desc_ru = await translate_text(desc, dest="ru")
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    return f"üé≤ <b>{title_ru}</b>\n\n{desc_ru}"

async def get_all_flavor_notes() -> List[str]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–∫—É—Å–æ–≤—ã–µ –Ω–æ—Ç—ã —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞.
    
    Returns:
        –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ç –≤–∫—É—Å–∞
    """
    page = 1
    notes_set = set()  # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ç

    # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
    while True:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        url = TASTY_URL_TEMPLATE.format(page)
        async with aiohttp.ClientSession() as session:
            html = await fetch_html(session, url)
        if not html:  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å
            break

        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(html, "html.parser")
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã
        items = soup.select("div.product-item")
        if not items:  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤
            break
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–æ–¥—É–∫—Ç
        for item in items:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –æ–ø–∏—Å–∞–Ω–∏—è
            desc_container = item.select_one("div.tc-tile__description")
            if not desc_container:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è
                
            # –ù–∞—Ö–æ–¥–∏–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
            description_p = desc_container.find("p")
            if not description_p:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
                
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –Ω–æ—Ç—ã –≤–∫—É—Å–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ
            for span in description_p.select("span.descriptor-badge"):
                notes_set.add(span.get_text(strip=True).lower())  # –í –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        
        page += 1  # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ç
    return sorted(notes_set)

async def find_coffee_by_flavors(flavors: List[str]) -> List[str]:
    """
    –ò—â–µ—Ç –∫–æ—Ñ–µ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –≤–∫—É—Å–æ–≤—ã–º –Ω–æ—Ç–∞–º.
    
    Args:
        flavors: –°–ø–∏—Å–æ–∫ –≤–∫—É—Å–æ–≤—ã—Ö –Ω–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ —Å –ø–æ–¥—Ö–æ–¥—è—â–∏–º–∏ –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏
    """
    page = 1
    results: List[str] = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    # –û—á–∏—â–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–∫—É—Å—ã (–Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤)
    user_flavors = [f.strip().lower() for f in flavors if f.strip()]

    # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
    while True:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        url = TASTY_URL_TEMPLATE.format(page)
        async with aiohttp.ClientSession() as session:
            html = await fetch_html(session, url)
        if not html:  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å
            break

        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(html, "html.parser")
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã
        items = soup.select("div.product-item")
        if not items:  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤
            break

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–æ–¥—É–∫—Ç
        for item in items:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞
            title_tag = item.select_one("div.tc-tile__title a")
            if not title_tag:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è

            # –ü–æ–ª—É—á–∞–µ–º –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ
            name_en = title_tag.get_text(separator=" ", strip=True)
            name_ru = await translate_text(name_en, dest="ru")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É
            link = BASE_URL + title_tag.get("href", "")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
            price_tag = item.select_one("span.text-nowrap")
            price_text = price_tag.get_text(strip=True) if price_tag else "‚Äî"  # –¢–µ–∫—Å—Ç —Ü–µ–Ω—ã

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            desc_container = item.select_one("div.tc-tile__description")
            if not desc_container:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è
                
            # –ù–∞—Ö–æ–¥–∏–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
            description_p = desc_container.find("p", class_="text-[14px]")
            if not description_p:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
                
            # –ü–æ–ª—É—á–∞–µ–º –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ
            description_en = description_p.get_text(separator=" ", strip=True)
            description_ru = await translate_text(description_en, dest="ru")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –Ω–æ—Ç—ã –≤–∫—É—Å–∞ (–≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
            notes = [s.get_text(strip=True).lower() for s in description_p.select("span.descriptor-badge")]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤—Å–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–º –≤–∫—É—Å–∞–º
            match = True
            for uf in user_flavors:
                words = uf.split()  # –†–∞–∑–±–∏–≤–∞–µ–º –≤–∫—É—Å –Ω–∞ —Å–ª–æ–≤–∞
                found_this_flavor = False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –Ω–æ—Ç—É –ø—Ä–æ–¥—É–∫—Ç–∞
                for note in notes:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –Ω–æ—Ç–∞ –≤—Å–µ —Å–ª–æ–≤–∞ –≤–∫—É—Å–∞
                    if all(word in note for word in words):
                        found_this_flavor = True
                        break
                
                # –ï—Å–ª–∏ —Ö–æ—Ç—å –æ–¥–∏–Ω –≤–∫—É—Å –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–¥—É–∫—Ç –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç
                if not found_this_flavor:
                    match = False
                    break

            # –ï—Å–ª–∏ –ø—Ä–æ–¥—É–∫—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –≤–∫—É—Å–∞–º - –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if match:
                results.append(
                    f"‚òï <b>{name_ru}</b>\n"
                    f"–í–∫—É—Å—ã: {', '.join(notes)}\n"
                    f"üí∞ –¶–µ–Ω–∞: {price_text}\n"
                    f"‚ÑπÔ∏è <i>{description_ru}</i>\n\n"
                    f"üîó <a href=\"{link}\">–°—Å—ã–ª–∫–∞</a>"
                )

        page += 1  # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    return results or ["–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."]